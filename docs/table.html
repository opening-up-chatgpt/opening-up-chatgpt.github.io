<table>
<thead>
<tr class="main-header"><th>Project</th><th colspan="6">Availability</th><th colspan="6">Documentation</th><th colspan="2">Access</th></tr>
<tr class="second-header"><th>(maker, bases, URL)</th><th>Open code</th><th>LLM data</th><th>LLM weights</th><th>RLHF data</th><th>RLHF weights</th><th>License</th><th>Code</th><th>Architecture</th><th>Preprint</th><th>Paper</th><th>Modelcard</th><th>Datasheet</th><th>Package</th><th>API</th></tr>
</thead>
<tbody>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf" title="">xmtf</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf" title="Repository provides a guided overview to all components">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf#data" title="Data made available & documented in detail in repo and preprint">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf#models" title="Model made available on github">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/datasets/bigscience/xP3all" title="From the documentation: 'xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks'">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/bigscience/bloomz-optimizer-states/tree/main" title="Fine-tuned checkpoint available for download">~</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf/blob/master/LICENSE.md" title="Apache 2.0">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf" title="Code well documented and actively maintained">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/bigscience-workshop/xmtf#create-xp3x" title="Architecture described in preprint, code available in github repo, recipe on HuggingFace">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://arxiv.org/abs/2211.01786" title="Preprint (updated May 2023) of 9 pages +114 page appendix">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/bigscience/bloomz" title="Model card ">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://github.com/bigscience-workshop" title="bigscience-workshop">bigscience-workshop</a></td><td colspan="3" class="llmbase">LLM base: BLOOMZ, mT0</td><td colspan="3" class="rlbase">RL base: xP3</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://huggingface.co/togethercomputer/Pythia-Chat-Base-7B" title="">OpenChatKit</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/togethercomputer/OpenDataHub" title="Training data curated and shared in separate repository">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/togethercomputer/Pythia-Chat-Base-7B/tree/main" title="Model weights available via HuggingFace">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/datasets/laion/OIG" title="From the documentation: 'This is our attempt to create a large instruction dataset of medium quality along with a smaller high quality instruciton dataset (OIG-small-chip2).'">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="RL weights not separately made available">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/togethercomputer/Pythia-Chat-Base-7B#model-details" title="Apache 2.0">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/togethercomputer/OpenChatKit" title="Actively maintained repository">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/togethercomputer/OpenChatKit#reproducing-pythia-chat-base-7b" title="Architecture and recipe for reproducing model provided">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs/2304.01373" title="Preprint describes LM base (Pythia) but not instruction tuning details">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="No peer-reviewed paper or data audit found">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/togethercomputer/Pythia-Chat-Base-7B" title="Model card partially available but fairly minimally specified">~</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/datasets/laion/OIG" title="OIG instruction dataset documented">~</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://github.com/togethercomputer" title="togethercomputer">togethercomputer</a></td><td colspan="3" class="llmbase">LLM base: EleutherAI pythia</td><td colspan="3" class="rlbase">RL base: OIG</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://open-assistant.io/" title="">Open Assistant</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/LAION-AI/Open-Assistant" title="Code includes guide for developers">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/LAION-AI/Open-Assistant/tree/main/data/datasets" title="Datasets documented in detail and recipes for cleaning up and downloading provided in code notebooks.">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/OpenAssistant" title="Model weights in several variants downloadable through HuggingFace">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/datasets/OpenAssistant/oasst1" title="OpenAssistant Conversations is 'a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings' (preprint)">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="RLHF weights not separately released">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="https://projects.laion.ai/Open-Assistant/docs/faq#what-license-does-open-assistant-use" title="Apache 2.0">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://projects.laion.ai/Open-Assistant/docs/intro" title="Separate website provides entry point to comprehensive documentation">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/LAION-AI/Open-Assistant/tree/main/model" title="Instructions to tune the pipeline on training data">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs//2304.07327" title="Preprint describes creation of OpenAssistant Conversations corpus for instruction tuning, but not the base LLM, hence partial.">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="No peer-reviewed paper or published data audit found">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://projects.laion.ai/Open-Assistant/api" title="">&#10004;&#xFE0E</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://open-assistant.io/" title="LAION-AI">LAION-AI</a></td><td colspan="3" class="llmbase">LLM base: Pythia 12B</td><td colspan="3" class="rlbase">RL base: OpenAssistant Conversations</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/databrickslabs/dolly" title="">dolly</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs/2304.01373" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://www.databricks.com" title="databricks">databricks</a></td><td colspan="3" class="llmbase">LLM base: EleutherAI pythia</td><td colspan="3" class="rlbase">RL base: databricks-dolly-15k</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://huggingface.co/tiiuae/falcon-40b-instruct" title="">Falcon-40B-instruct</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/tiiuae/falcon-40b-instruct" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb" title="From the documentation: 'The key ingredient for the high quality of the Falcon models is their training data, predominantly based (>80%) on RefinedWeb â€” a novel massive web dataset based on CommonCrawl' (https://huggingface.co/blog/falcon). However, only a small sample is made available.">~</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/tiiuae/falcon-40b-instruct/tree/main" title="Model weights available through HuggingFace library">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/project-baize/baize-chatbot" title="RL data inherited from Baize but provenance not well-documented. From the documentation: 'Falcon-40B-Instruct was finetuned on a 150M tokens from Baize mixed with 5% of RefinedWeb data.'">~</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/project-baize/baize-chatbot#v1" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="First release came with a legally murky license that was swiftly criticised and now generates a 404. Current documentation: 'Falcon-40B-Instruct is made available under the Apache 2.0 license.'">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs/2306.01116" title="Preprint covers the creation and curation of RefinedWeb dataset, but not other aspects of the model, hence partial.">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="No peer-reviewed paper known.">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://falconllm.tii.ae" title="Technology Innovation Institute">Technology Innovation Institute</a></td><td colspan="3" class="llmbase">LLM base: Falcon 40B</td><td colspan="3" class="rlbase">RL base: Baize (synthetic)</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/CarperAI/trlx" title="">trlx</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://github.com/CarperAI/trlx" title="carperai">carperai</a></td><td colspan="3" class="llmbase">LLM base: various (pythia, flan, OPT) </td><td colspan="3" class="rlbase">RL base: various</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://huggingface.co/lmsys/vicuna-13b-v1.3" title="'Vicuna is a chat assistant trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.'">Vicuna 13B v 1.3</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat" title="Actively maintained repository">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md#training-dataset" title="Vicuna is fine-tuned LLaMA, and LLaMA in turn is based on 'publicly available datasets' that are not all specified or easily downloadable.">~</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat#vicuna-weights" title="Unlike Vicuna 13B v0, these weights do not require applying delta">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat#fine-tuning" title="From the documentation: 'We will not release the ShareGPT dataset'. Also: 'Vicuna v1.3 is fine-tuned from LLaMA with supervised instruction fine-tuning. The training data is around 140K conversations collected from ShareGPT.com.'">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat#fine-tuning" title="No model weights are shared for the instruction tuning">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat#vicuna-weights" title="From the documentation: 'Vicuna is based on LLaMA and should be used under LLaMA's model license.'">~</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat" title="Code is quite well-documented and released as part of the FastChat framework.">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="https://arxiv.org/pdf/2306.05685.pdf" title="Preprint covers training of the Vicuna model.">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="No peer-reviewed paper.">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/lmsys/vicuna-13b-v1.3" title="Minimal model card, but many details are not provided or have to be pieced together from elsewhere.">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="No datasheet provided.">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="https://pypi.org/project/fschat/0.1.2/" title="Available via pip">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/lm-sys/FastChat#api" title="Support provided for several APIs: OpenAI restful, HuggingFace, Langchain">~</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://lmsys.org/" title="LMSYS">LMSYS</a></td><td colspan="3" class="llmbase">LLM base: LLaMA</td><td colspan="3" class="rlbase">RL base: ShareGPT</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="hhttps://github.com/ethanyanjiali/minChatGPT" title="">minChatGPT</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://github.com/ethanyanjiali/minChatGPT" title="ethanyanjiali">ethanyanjiali</a></td><td colspan="3" class="llmbase">LLM base: GPT2</td><td colspan="3" class="rlbase">RL base: anthropic</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/BlinkDL/ChatRWKV" title="">ChatRWKV</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/BlinkDL/ChatRWKV" title="Various community-contributed enhancements available">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://pile.eleuther.ai/" title="Trained on The Pile. Recent versions also build on Red Pajama (https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T)">~</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/BlinkDL/rwkv-4-world/tree/main" title="Model weights released across different HuggingFace spaces">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="Instruction tuning data not separately available. Documentation: 'These are RWKV-4-Pile 1.5/3/7/14B models finetuned on Alpaca, CodeAlpaca, Guanaco, GPT4All, ShareGPT and more'">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="Weights not separately available.">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/BlinkDL/ChatRWKV/blob/main/LICENSE" title="Apache 2.0">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="Code documentation scattered across github repo and HuggingFace spaces">~</a></td><td class="partial data-cell"><a target="_blank" href="" title="Architecture described in preprint (LM part) but not all details clearly documented.">~</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs/2305.13048" title="Preprint covers only LLM (RNN based), not instruction fine-tuning, so partial.">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="No peer-reviewed paper or published data audit known">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="https://huggingface.co/BlinkDL/rwkv-4-raven" title="No modelcard, HuggingFace spaces only used to share files">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="https://huggingface.co/BlinkDL/rwkv-4-raven" title="No data sheet, HuggingFac spaces only used to share files">&#10008;</a></td><td class="open data-cell"><a target="_blank" href=" https://pypi.org/project/rwkv/" title="Available through pip: pip install rwkv">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="API via HuggingFace">~</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://www.rwkv.com/" title="BlinkDL/RWKV">BlinkDL/RWKV</a></td><td colspan="3" class="llmbase">LLM base: RWKV-LM</td><td colspan="3" class="rlbase">RL base: alpaca, shareGPT (synthetic)</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/Cerebras" title="">Cerebras-GPT-111M</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs/2304.03208" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://github.com/Cerebras" title="Cerebras + Schramm">Cerebras + Schramm</a></td><td colspan="3" class="llmbase">LLM base: </td><td colspan="3" class="rlbase">RL base: Alpaca (synthetic)</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://www.mosaicml.com/blog/mpt-7b" title="">MPT-7B</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="https://huggingface.co/mosaicml/mpt-7b-instruct" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://www.mosaicml.com" title="MosaicML">MosaicML</a></td><td colspan="3" class="llmbase">LLM base: MosaicML</td><td colspan="3" class="rlbase">RL base: dolly, anthropic</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/LianjiaTech/BELLE" title="">BELLE</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="LLaMA based but copyright status unclear">~</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="LLaMA licence agreement">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://arxiv.org/abs/2303.14742" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="http://www.ke.com" title="KE Technologies">KE Technologies</a></td><td colspan="3" class="llmbase">LLM base: LLaMA & BLOOMZ</td><td colspan="3" class="rlbase">RL base: alpaca & shareGPT (synthetic)</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://github.com/oobabooga/text-generation-webui" title="">text-generation-webui</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/models?sort=downloads&search=eleutherai%2Fpythia+deduped" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://oobabooga.github.io" title="Oobabooga">Oobabooga</a></td><td colspan="3" class="llmbase">LLM base: various</td><td colspan="3" class="rlbase">RL base: various</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://crfm.stanford.edu/2023/03/13/alpaca.html" title="">Stanford Alpaca</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca#data-release" title="">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="" title="LLaMA based, copyright status unclear">~</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca#data-release" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca#data-release" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform" title="LLaMA licence agreement">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="open data-cell"><a target="_blank" href="" title="">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="partial data-cell"><a target="_blank" href="" title="">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://crfm.stanford.edu/" title="Stanford University CRFM">Stanford University CRFM</a></td><td colspan="3" class="llmbase">LLM base: LLaMA</td><td colspan="3" class="rlbase">RL base: Self-Instruct</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://bair.berkeley.edu/blog/2023/04/03/koala/" title="From the documentation: 'Koala is fine-tuned on freely available interaction data scraped from the web, but with a specific focus on data that includes interaction with highly capable closed-source models such as ChatGPT.'">Koala 13B</a></td><td class="open data-cell"><a target="_blank" href="https://github.com/young-geng/EasyLM" title="Code scattered across projects and repositories">&#10004;&#xFE0E</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/young-geng/koala_data_pipeline" title="Repo contains data pipeline for preprocessing. Based on LLaMA which is said to be based on 'publicly available datasets' which are not made directly available.">~</a></td><td class="partial data-cell"><a target="_blank" href="https://drive.google.com/drive/folders/10f7wrlAFoPIy-TECHsx9DKIvbQYunCfl" title="Model weights only made available as a diff against LLaMA. OpenLLaMA provides a possible alternative?">~</a></td><td class="partial data-cell"><a target="_blank" href="https://bair.berkeley.edu/blog/2023/04/03/koala/#datasets-and-training" title="Datasets described in blog post but not all made available">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="RL weights not made available separately">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/young-geng/koala#license" title="Licensing is 'subject to the model License of LLaMA, Terms of Use of the data generated by OpenAI, and Privacy Practices of ShareGPT'">~</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/young-geng/EasyLM" title="Code scattered across various repositories and not systematically documented.">~</a></td><td class="partial data-cell"><a target="_blank" href="https://github.com/young-geng/EasyLM" title="Architecture visually illustrated and described in some detail.">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="No preprint available">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="No peer-reviewed paper">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="No model card available">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="No systematic data sheet available">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="No package available">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="No API available">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://bair.berkeley.edu/" title="BAIR">BAIR</a></td><td colspan="3" class="llmbase">LLM base: LLaMA 13B</td><td colspan="3" class="rlbase">RL base: HC3, ShareGPT, alpaca (synthetic)</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta" title="StableVicuna-13B is a Vicuna-13B v0 model fine-tuned using reinforcement learning from human feedback (RLHF) via Proximal Policy Optimization (PPO) on various conversational and instructional datasets">StableVicuna-13B</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta/tree/main" title="Some elements of the code made available through HuggingFace">~</a></td><td class="open data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta" title="All datasets are available and linked. StableVicuna-13B is fine-tuned on a mix of three datasets. OpenAssistant Conversations Dataset (OASST1), a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages; GPT4All Prompt Generations, a dataset of 400k prompts and responses generated by GPT-4; and Alpaca, a dataset of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine.">&#10004;&#xFE0E</a></td><td class="closed data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta#apply-delta-weights" title="Model not functional out of the box as weights require a delta computation. From the docs: 'StableVicuna-13B cannot be used from the CarperAI/stable-vicuna-13b-delta weights alone. To obtain the correct model, one must add back the difference between LLaMA 13B and CarperAI/stable-vicuna-13b-delta weights.'">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta" title="From the documentation: 'The reward model used during RLHF was also trained on OpenAssistant Conversations Dataset (OASST1) along with two other datasets: Anthropic HH-RLHF, a dataset of preferences about AI assistant helpfulness and harmlessness; and Stanford Human Preferences Dataset a dataset of 385K collective human preferences over responses to questions/instructions in 18 different subject areas, from cooking to legal advice.'">~</a></td><td class="closed data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta/discussions/7" title="The HuggingFace community page has an open question for release of the RL model">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta" title="CC-BY-NC-SA-4.0. License for LLaMA is more murky, hence partial. As they say: 'License for the base LLaMA model's weights is Meta's non-commercial bespoke license.'">~</a></td><td class="partial data-cell"><a target="_blank" href="https://huggingface.co/CarperAI/stable-vicuna-13b-delta/tree/main" title="Code is minimally documented and deployment requires non-trivial configuration, e.g. 'StableVicuna-13B cannot be used from the CarperAI/stable-vicuna-13b-delta weights alone. To obtain the correct model, one must add back the difference between LLaMA 13B and CarperAI/stable-vicuna-13b-delta weights.'">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="partial data-cell"><a target="_blank" href="https://arxiv.org/abs/2302.13971" title="Preprint covers only the LLaMA base model, hence partial.">~</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://carper.ai" title="CarperAI">CarperAI</a></td><td colspan="3" class="llmbase">LLM base: LLaMA</td><td colspan="3" class="rlbase">RL base: OASST1 (human), GPT4All (human), Alpaca (synthetic)</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="https://chat.openai.com/" title="NA">ChatGPT</a></td><td class="closed data-cell"><a target="_blank" href="https://chat.openai.com/" title="OpenAI has not released any source code related to ChatGPT">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="https://openai.com/" title="OpenAI">OpenAI</a></td><td colspan="3" class="llmbase">LLM base: GPT 3.5</td><td colspan="3" class="rlbase">RL base: Instruct-GPT</td></tr>
<tr class="row-a"><td class="name-cell"><a target="_blank" href="" title=""></a></td><td class=" data-cell"><a target="_blank" href="" title="">?</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td><td class="closed data-cell"><a target="_blank" href="" title="">&#10008;</a></td></tr>
<tr class="row-b"><td class="org"><a target="_blank" href="" title=""></a></td><td colspan="3" class="llmbase">LLM base: </td><td colspan="3" class="rlbase">RL base: </td></tr>
</tbody>
</table>
