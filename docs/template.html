<!DOCTYPE html>
<html>
<head>
  <title>Opening up ChatGPT: tracking openness, transparency, and accountability in instruction-tuned text generators</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="icon" type="image/x-icon" href="favicon.png">
<script defer data-domain="opening-up-chatgpt.github.io" src="https://plausible.io/js/script.js"></script>

</head>
<body>
	<div id="header">
		<h1><a href="" title="Opening up ChatGPT: tracking openness, transparency, and accountability in instruction-tuned text generators"><img alt="Opening up AI logo" id="title-logo" src="logos/openchatgpt-logo-favicon-red-on-transparent.png"/>Opening up ChatGPT</a></h1>
	</div>
	<div id="content">
  		<p>There is a growing amount of instruction-tuned text generators billing themselves as 'open source'. How open are they really?</p>
		<p class="warning"><strong>Note</strong>: This is a soft launch. The paper will be available soon. Get in touch with <a href="mailto:mark.dingemanse@ru.nl">mark.dingemanse@ru.nl</a> for a sneak preview.</p>
		<!--<p>Check out <a href="https://doi.org/10.1145/3571884.3604316" target="_blank">the paper</a> or contribute to <a href="https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io/">the repo</a>.</p>-->

  <div id="included-table"></div>

	<p id="table-guide"><em>How to use this table.</em> Every cell records a three-level openness judgement (<span class="openness open"><strong>✔︎</strong> open</span>, <span class="openness partial"><strong>~</strong> partial</span> or <span class="openness closed"><strong>✘</strong> closed</span>) with a direct link to the available evidence; on hover, the cell will display the notes we have on file for that judgement. At the end of a row, the <strong>§</strong> is a direct link to source data. The table is sorted by cumulative openness, where <strong>✔︎</strong> is 1, <strong>~</strong> is 0.5 and <strong>✘</strong> is 0 points.</p>

		<h2>Why is openness important?</h2>
		<p>Open research is the lifeblood of cumulative progress in science and engineering. Openness is key for fundamental research, for fostering critical computational literacy, and for making informed choices for or against deployment of LLM+RLHF architectures. The closed & proprietary nature of ChatGPT and kin makes them fundamentally unfit for responsible use in research and education.</p>
		<p>Open alternatives provide ways to build reproducible workflows, chart resource costs, and lessen reliance on corporate whims. One aim of our work here is to provide tools to track openness, transparency and accountability in the fast-evolving landscape of instruction-tuned text generators. Read more in the paper.</p>

<h2>How to contribute</h2>
<p>If you know a model that should be listed here or a data point that needs updating, please see <a href="https://github.com/opening-up-chatgpt/">guidelines for contributors</a>. We welcome any contribution, whether it's a quick addition to our <a href="https://github.com/opening-up-chatgpt/opening-up-chatgpt">awesomelist</a> or a more detail-oriented contribution to the metadata for a <a href="https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io/tree/main/projects">specific project</a>.</p>
<h2>Useful? Read &amp; cite the paper</h2>
<p>Liesenfeld, Andreas, Alianda Lopez, and Mark Dingemanse. 2023. “Opening up ChatGPT: Tracking Openness, Transparency, and Accountability in Instruction-Tuned Text Generators.” In <em>Proceedings of CUI’23</em>. July 19-21, Eindhoven. doi: 10.1145/3571884.3604316.</p>
<h2>TL;DR</h2>
<p>Our paper makes the following contributions:</p>
<ul>
<li>We review the risks of relying on proprietary software</li>
<li>We review best practices for open, transparent and accountable 'AI'</li>
<li>We find over 15 ChatGPT alternatives at varying degrees of openness, development and documentation</li>
<li>We argue that tech is never a <em>fait accompli</em> unless we make it so, and that openness enables critical computational literacy</li>
</ul>
<p>We find the following recurrent patterns:</p>
<ul>
<li>Many projects inherit data of dubious legality</li>
<li>Few projects share the all-important instruction-tuning</li>
<li>Preprints are rare, peer-reviewed papers even rarer</li>
<li>Synthetic instruction-tuning data is on the rise, with unknown consequences that are in need of research</li>
</ul>
<p>We conclude as follows:</p>
<blockquote id="conclusion">Openness is not the full solution to the scientific and ethical challenges of conversational text generators. Open data will not mitigate the harmful consequences of thoughtless deployment of large language models, nor the questionable copyright implications of scraping all publicly available data from the internet. However, openness does make original research possible, including efforts to build reproducible workflows and understand the fundamentals of LLM + RLHF architectures. Openness also enables checks and balances, fostering a culture of accountability for data and its curation, and for models and their deployment. We hope that our work provides a small step in this direction.
  </blockquote>
</div><!-- #content -->
<div id="footer">
<p>We gratefully acknowledge funding from the Dutch Research Council for the project <em><a href="https://markdingemanse.net/elpaco" target="_blank">Elementary Particles of Conversation</a></em> (016.vidi.185.205), and support from the CLS Humanities Lab (<a href="https://github.com/timjzee/" target="_blank">timjzee</a>)</p>
<p class="copyright">Website &amp; code © 2023 by the authors. If you find any of this useful, the paper provides the canonical and most durable citation.</p>
<p id="build-time">Table last built on 2023-07-05 at 07:15 UTC</p>
</div>
</body>
</html>
